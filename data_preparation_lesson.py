# -*- coding: utf-8 -*-
"""Data Preparation lesson.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cbvlov_VR2HgI8CsqqBOtK0xEFBgPVpo

## Data Preparation

Importing libraries
"""

import pandas as pd
import numpy as np
import seaborn as sns

url = "https://covid.ourworldindata.org/data/owid-covid-data.csv"
df = pd.read_csv(url)
df.head()

"""##Getting to know your dataset"""

#describing data set
df.describe()

#shape my dataset
#it tells you how many rows and columns in your data
df.shape

"""##Handling Duplicates"""

#check duplicated
df.duplicated().sum()
df.drop_duplicates(inplace=True) #this removes the repetitions if there are any

"""##Handling Null Values"""

#check null values
df.isnull().sum()
#null values are columns  that have no data and that you don't need in your table.

"""##Dropping Nulls"""

df.dropna(inplace=True) #removing the null values
dfl = df.dropna(subset = ['total_cases'])

"""##Imputation"""

#Numerical Values
#using mean
df['total_case'] = df['total_cases'].fillna(df['total_cases'].mean())

#now use median to impute null values
df['total_case'] = df['total_cases'].fillna(df['total_cases'].median())

"""##Categorical Values"""

#Categorical Values
#Select any Column with Categorical Values, impute using mode
df['location'] = df['location'].fillna(df['location'].mode())

"""##Dropping Columns"""

#drop column named iso_code
df.drop('iso_code', axis=1, inplace=True)
#drop column new_deaths_smoothed
df.drop('new_deaths_smoothed', axis=1, inplace=True)

"""##Getting a Subset of your Data"""

#get subset data for Zimbabwe and Rwanda
subset = df[(df['location'] == 'Zimbabwe') | (df['location'] == 'Rwanda')]
#displaying the subset
subset.head()

"""##Let's Save Our Data Cleaned"""

#saving the data
df.to_csv('url')